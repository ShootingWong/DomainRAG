Namespace(name='experiment_name', llm_name='llama', log_path='', checkpoint_dir='./checkpoint/', model_path='', per_gpu_batch_size=1, per_gpu_eval_batch_size=1, seed=0, log_freq=100, eval_freq=500, save_freq=5000, html_root='', docs_root='', train_data='', eval_data='', test_data='', test_save_path='', openai_api='', apikey='', is_encoder_decoder=False, is_eval=False, is_test=False, reader_model_path=None, text_maxlength=200, q_maxlength=200, d_maxlength=200, retriever_n_context=50, passages_root='', passages=None, max_passages=-1, sample_times=1, infer_batch=2, rank_model_path='facebook/contriever', vllm=False, fastchat=False, gpt=False, baichuan=False, infer_type='fastchat', psg_pmt='Title:{title}. Content:{text}', llm_pmt='Background:{docs}. Question:{query}. Answer:', close_pmt='Background:{docs}. Question:{query}. Answer:', conv_pmt='**Given Information:**\n{docs}\n**Question:**\n{query}\n**Answer:**\n{answer}\n', query_instruct='', generation_max_length=128, generation_min_length=None, generation_length_penalty=1.0, generation_num_beams=1, task='basic', knowledge_type=None, gen_temperature=0, top_p=0.95, stop_words=['。'], warmup_steps=1000, K_epochs=3, max_episodes=3, total_steps=1000, scheduler_steps=None, accumulation_steps=1, dropout=0.1, lr=0.0001, lr_retriever=1e-05, clip=1.0, scheduler='cosine', weight_decay=0.1, save_optimizer=False, shuffle=False, precision='fp32', html_roots=[''], text_roots=['../../corpus/rdzs/json_output'], retriever_type='bm25', retrieved_topk=20, retrieve_data_path='../labeled_data/extractive_qa/basic_qa.jsonl', retrieve_save_path='../labeled_data/extractive_qa/basic_qa_retrieved_bm25_test.jsonl', query_encoder_path='/cpfs01/user/bc_search_intern/wangshuting/plms/', context_encoder_path='/cpfs01/user/bc_search_intern/wangshuting/plms/', gpu_embedder_batch_size=512, retriever_format='{title}。{contents}', noisy_cnt=1, noisy_gold_idx=0, repeat=0)
---------------Begin to Load TEXT Corpus---------------
  0%|                                                                                                                       | 0/1686 [00:00<?, ?it/s]  6%|██████▍                                                                                                     | 100/1686 [00:00<00:01, 979.31it/s] 12%|█████████████▏                                                                                             | 208/1686 [00:00<00:01, 1028.65it/s] 19%|████████████████████▌                                                                                      | 324/1686 [00:00<00:01, 1087.41it/s] 27%|████████████████████████████▉                                                                              | 456/1686 [00:00<00:01, 1177.87it/s] 34%|████████████████████████████████████▋                                                                      | 578/1686 [00:00<00:00, 1189.84it/s] 41%|████████████████████████████████████████████▎                                                              | 698/1686 [00:00<00:00, 1136.15it/s] 50%|█████████████████████████████████████████████████████                                                      | 836/1686 [00:00<00:00, 1212.37it/s] 58%|██████████████████████████████████████████████████████████████▌                                            | 986/1686 [00:00<00:00, 1299.98it/s] 66%|██████████████████████████████████████████████████████████████████████▍                                   | 1121/1686 [00:00<00:00, 1314.49it/s] 74%|██████████████████████████████████████████████████████████████████████████████▊                           | 1253/1686 [00:01<00:00, 1282.53it/s] 82%|██████████████████████████████████████████████████████████████████████████████████████▉                   | 1382/1686 [00:01<00:00, 1222.38it/s] 90%|███████████████████████████████████████████████████████████████████████████████████████████████▌          | 1520/1686 [00:01<00:00, 1267.44it/s] 99%|████████████████████████████████████████████████████████████████████████████████████████████████████████▊ | 1667/1686 [00:01<00:00, 1324.74it/s]100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1686/1686 [00:01<00:00, 1239.75it/s]
---------------Load TEXT Corpus Over---------------
-------------Begin to Load data from ../labeled_data/extractive_qa/basic_qa.jsonl-------------
Building prefix dict from the default dictionary ...
Dumping model to file cache /tmp/jieba.cache
Loading model cost 0.483 seconds.
Prefix dict has been built successfully.
-------------Begin to save retrieved results-------------
-------------Save retrieved results over-------------
Namespace(name='experiment_name', llm_name='llama', log_path='', checkpoint_dir='./checkpoint/', model_path='', per_gpu_batch_size=1, per_gpu_eval_batch_size=1, seed=0, log_freq=100, eval_freq=500, save_freq=5000, html_root='', docs_root='', train_data='', eval_data='', test_data='', test_save_path='', openai_api='', apikey='', is_encoder_decoder=False, is_eval=False, is_test=False, reader_model_path=None, text_maxlength=200, q_maxlength=200, d_maxlength=200, retriever_n_context=50, passages_root='', passages=None, max_passages=-1, sample_times=1, infer_batch=2, rank_model_path='facebook/contriever', vllm=False, fastchat=False, gpt=False, baichuan=False, infer_type='fastchat', psg_pmt='Title:{title}. Content:{text}', llm_pmt='Background:{docs}. Question:{query}. Answer:', close_pmt='Background:{docs}. Question:{query}. Answer:', conv_pmt='**Given Information:**\n{docs}\n**Question:**\n{query}\n**Answer:**\n{answer}\n', query_instruct='为这个句子生成表示以用于检索相关文章：{}', generation_max_length=128, generation_min_length=None, generation_length_penalty=1.0, generation_num_beams=1, task='basic', knowledge_type=None, gen_temperature=0, top_p=0.95, stop_words=['。'], warmup_steps=1000, K_epochs=3, max_episodes=3, total_steps=1000, scheduler_steps=None, accumulation_steps=1, dropout=0.1, lr=0.0001, lr_retriever=1e-05, clip=1.0, scheduler='cosine', weight_decay=0.1, save_optimizer=False, shuffle=False, precision='fp32', html_roots=[''], text_roots=['../../corpus/rdzs/json_output'], retriever_type='dense', retrieved_topk=20, retrieve_data_path='../labeled_data/extractive_qa/basic_qa.jsonl', retrieve_save_path='../labeled_data/extractive_qa/basic_qa_retrieved_dense_test.jsonl', query_encoder_path='/cpfs01/user/bc_search_intern/wangshuting/plms/bge-base-zh-v1.5', context_encoder_path='/cpfs01/user/bc_search_intern/wangshuting/plms/bge-base-zh-v1.5', gpu_embedder_batch_size=512, retriever_format='{title}。{contents}', noisy_cnt=1, noisy_gold_idx=0, repeat=0)
---------------Begin to Load TEXT Corpus---------------
  0%|                                                                                                                       | 0/1686 [00:00<?, ?it/s] 22%|███████████████████████▎                                                                                   | 367/1686 [00:00<00:00, 3658.07it/s] 43%|██████████████████████████████████████████████▌                                                            | 733/1686 [00:00<00:00, 3582.31it/s] 68%|████████████████████████████████████████████████████████████████████████▍                                 | 1153/1686 [00:00<00:00, 3837.64it/s] 91%|████████████████████████████████████████████████████████████████████████████████████████████████▋         | 1537/1686 [00:00<00:00, 3769.07it/s]100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 1686/1686 [00:00<00:00, 3783.90it/s]
---------------Load TEXT Corpus Over---------------
------------Building Index Ing------------
  0%|                                                                                                                         | 0/29 [00:00<?, ?it/s]embeddings size = torch.Size([512, 768])
  3%|███▉                                                                                                             | 1/29 [00:01<00:32,  1.16s/it]embeddings size = torch.Size([512, 768])
  7%|███████▊                                                                                                         | 2/29 [00:01<00:23,  1.13it/s]embeddings size = torch.Size([512, 768])
 10%|███████████▋                                                                                                     | 3/29 [00:02<00:20,  1.25it/s]embeddings size = torch.Size([512, 768])
 14%|███████████████▌                                                                                                 | 4/29 [00:03<00:18,  1.32it/s]embeddings size = torch.Size([512, 768])
 17%|███████████████████▍                                                                                             | 5/29 [00:03<00:17,  1.36it/s]embeddings size = torch.Size([512, 768])
 21%|███████████████████████▍                                                                                         | 6/29 [00:04<00:16,  1.39it/s]embeddings size = torch.Size([512, 768])
 24%|███████████████████████████▎                                                                                     | 7/29 [00:05<00:15,  1.41it/s]embeddings size = torch.Size([512, 768])
 28%|███████████████████████████████▏                                                                                 | 8/29 [00:06<00:14,  1.42it/s]embeddings size = torch.Size([512, 768])
 31%|███████████████████████████████████                                                                              | 9/29 [00:06<00:13,  1.43it/s]embeddings size = torch.Size([512, 768])
 34%|██████████████████████████████████████▌                                                                         | 10/29 [00:07<00:13,  1.44it/s]embeddings size = torch.Size([512, 768])
 38%|██████████████████████████████████████████▍                                                                     | 11/29 [00:08<00:12,  1.44it/s]embeddings size = torch.Size([512, 768])
 41%|██████████████████████████████████████████████▎                                                                 | 12/29 [00:08<00:11,  1.45it/s]embeddings size = torch.Size([512, 768])
 45%|██████████████████████████████████████████████████▏                                                             | 13/29 [00:09<00:11,  1.45it/s]embeddings size = torch.Size([512, 768])
 48%|██████████████████████████████████████████████████████                                                          | 14/29 [00:10<00:10,  1.45it/s]embeddings size = torch.Size([512, 768])
 52%|█████████████████████████████████████████████████████████▉                                                      | 15/29 [00:10<00:09,  1.45it/s]embeddings size = torch.Size([512, 768])
 55%|█████████████████████████████████████████████████████████████▊                                                  | 16/29 [00:11<00:09,  1.41it/s]embeddings size = torch.Size([512, 768])
 59%|█████████████████████████████████████████████████████████████████▋                                              | 17/29 [00:12<00:08,  1.41it/s]embeddings size = torch.Size([512, 768])
 62%|█████████████████████████████████████████████████████████████████████▌                                          | 18/29 [00:12<00:07,  1.42it/s]embeddings size = torch.Size([512, 768])
 66%|█████████████████████████████████████████████████████████████████████████▍                                      | 19/29 [00:13<00:07,  1.42it/s]embeddings size = torch.Size([512, 768])
 69%|█████████████████████████████████████████████████████████████████████████████▏                                  | 20/29 [00:14<00:06,  1.42it/s]embeddings size = torch.Size([512, 768])
 72%|█████████████████████████████████████████████████████████████████████████████████                               | 21/29 [00:15<00:05,  1.43it/s]embeddings size = torch.Size([512, 768])
 76%|████████████████████████████████████████████████████████████████████████████████████▉                           | 22/29 [00:15<00:04,  1.43it/s]embeddings size = torch.Size([512, 768])
 79%|████████████████████████████████████████████████████████████████████████████████████████▊                       | 23/29 [00:16<00:04,  1.43it/s]embeddings size = torch.Size([512, 768])
 83%|████████████████████████████████████████████████████████████████████████████████████████████▋                   | 24/29 [00:17<00:03,  1.43it/s]embeddings size = torch.Size([512, 768])
 86%|████████████████████████████████████████████████████████████████████████████████████████████████▌               | 25/29 [00:17<00:02,  1.43it/s]embeddings size = torch.Size([512, 768])
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████▍           | 26/29 [00:18<00:02,  1.39it/s]embeddings size = torch.Size([512, 768])
 93%|████████████████████████████████████████████████████████████████████████████████████████████████████████▎       | 27/29 [00:19<00:01,  1.40it/s]embeddings size = torch.Size([512, 768])
 97%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▏   | 28/29 [00:20<00:00,  1.39it/s]embeddings size = torch.Size([70, 768])
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:20<00:00,  1.84it/s]14406 passages encoded index_embeddings size = torch.Size([14406, 768]) 
training index...
adding embeddings...
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 29/29 [00:20<00:00,  1.42it/s]
-------------Begin to Load data from ../labeled_data/extractive_qa/basic_qa.jsonl-------------
D shape = (90, 20) I shape = (90, 20)
-------------Begin to save retrieved results-------------
-------------Save retrieved results over-------------
